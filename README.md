# Housing-Prices-Prediction
This notebook is a compilation of the knowledge from Kaggle Machine Learning courses to generate a better submission to the Housing Prices Competition. First of all, the data will be imported from the Housing Prices Competition for Kaggle Learn Users and preprocessed using different techniques. We will select the best preprocess technique between Ordinal Encoder, One-hot Encoder or simply dropping out categorical data, by comparison of the Mean Absolute Error (MAE) of the predictions generated by each approach. Next, we will create a pipeline to implement the best preprocess more quickly, which will allow us to test different machine learning models. Then, we will compare the MAE of different Random Forest and improved models with Extreme Gradient Boost, varying the number of estimators and the learning rate. The model that results in the smallest MAE in validation data was submited to the Kaggle housing prices competition, ranking on top 5% of the leaderboard.
